{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMPQpbbrCU_d",
        "outputId": "64a9640c-4da5-4077-9ed6-ffdc43f699e8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "# resp = requests.get(\"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE/getUpdates\")    FOR PUSH TO GITHUB\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT2s-rWRIXa_"
      },
      "source": [
        "\n",
        "# read data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geq9KQwoG4GB",
        "outputId": "ae4f6245-602c-4f44-fb55-1ecf72f1822b"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "base_url = \"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE/getUpdates\"\n",
        "parameters = {\n",
        "    \"offset\": \"470695232\",\n",
        "    \"limit\": \"30\"\n",
        "\n",
        "}\n",
        "\n",
        "# resp = requests.get(\"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE/getUpdates\")\n",
        "resp = requests.get(base_url, data=parameters)\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TCvv6-1Iit2"
      },
      "source": [
        "# Send message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUzWMhrVIV7p",
        "outputId": "54cb3123-4370-4bbe-cf69-c8e6870678dc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "# base_url = \"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE/sendmessage\"    FOR PUSH TO GITHUB\n",
        "parameters = {\n",
        "    \"chat_id\": \"-4802805386\",\n",
        "    \"text\": \"Hello\"\n",
        "\n",
        "}\n",
        "\n",
        "# resp = requests.get(\"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE/getUpdates\")\n",
        "resp = requests.get(base_url, data=parameters)\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G2X5Z05TI5K"
      },
      "source": [
        "# Create Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Oqboui_Xtkm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# base_url = \"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE\"   FOR PUSH TO GITHUB\n",
        "\n",
        "\n",
        "\n",
        "def read_msg():\n",
        "\n",
        "  parameters = {\n",
        "      \"offset\" : \"470695239\"\n",
        "  }\n",
        "\n",
        "  resp = requests.get(base_url + \"/getUpdates\", data = parameters)\n",
        "  data = resp.json()\n",
        "\n",
        "  for result in data[\"result\"]:\n",
        "    if \"hi\" in result[\"message\"][\"text\"]:\n",
        "      send_msg()\n",
        "\n",
        "\n",
        "def send_msg():\n",
        "  parameters = {\n",
        "      \"chat_id\" : \"-4802805386\",\n",
        "      \"text\" : \"Hello !!!\"\n",
        "  }\n",
        "\n",
        "  resp = requests.get(base_url + \"/sendMessage\", data = parameters)\n",
        "  print(resp.text)\n",
        "\n",
        "\n",
        "\n",
        "read_msg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "vXoajUfgjj16",
        "outputId": "2d91ef5f-8479-4b08-87ac-02aeca061dfb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "while True:\n",
        "    offset = read_msg(offset)\n",
        "    time.sleep(1)  # 1-second delay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1AOoixsUjnAP",
        "outputId": "ebfbdb21-276d-4075-ceda-29b4a4223f51"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!pip install fuzzywuzzy python-Levenshtein --quiet\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# Load bot token securely\n",
        "TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\")  # Set in environment\n",
        "# base_url = f\"https://api.telegram.org/bot7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE\"      FOR PUSH TO GITHUB \n",
        "\n",
        "# Load Q&A data\n",
        "url = 'https://raw.githubusercontent.com/arnavyadav002/blaze/refs/heads/main/QuestionAnswer2.tsv'\n",
        "df = pd.read_csv(url, sep=\"\\t\")\n",
        "\n",
        "def read_msg(offset):\n",
        "    try:\n",
        "        resp = requests.get(\n",
        "            base_url + \"/getUpdates\",\n",
        "            params={\"offset\": offset},\n",
        "            timeout=10\n",
        "        )\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "\n",
        "        for result in data[\"result\"]:\n",
        "            send_msg(result)\n",
        "\n",
        "        if data[\"result\"]:\n",
        "            return data[\"result\"][-1][\"update_id\"] + 1\n",
        "        return offset\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return offset\n",
        "\n",
        "def auto_answer(message):\n",
        "    matches = process.extractOne(message.lower(), df['Question'].str.lower())\n",
        "    if matches[1] > 80:  # 80% similarity threshold\n",
        "        return df.iloc[matches[2]]['Answer']\n",
        "    return \"Sorry, I didn't understand. Try rephrasing!\"\n",
        "\n",
        "def send_msg(message):\n",
        "    text = message[\"message\"][\"text\"]\n",
        "    chat_id = message[\"message\"][\"chat\"][\"id\"]\n",
        "    message_id = message[\"message\"][\"message_id\"]\n",
        "    answer = auto_answer(text)\n",
        "\n",
        "    try:\n",
        "        resp = requests.get(\n",
        "            base_url + \"/sendMessage\",\n",
        "            params={\n",
        "                \"chat_id\": chat_id,\n",
        "                \"text\": answer,\n",
        "                \"reply_to_message_id\": message_id\n",
        "            },\n",
        "            timeout=10\n",
        "        )\n",
        "        print(resp.text)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error sending message: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    offset = 0\n",
        "    while True:\n",
        "        offset = read_msg(offset)\n",
        "        time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZvg58irYhON"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/arnavyadav002/blaze/refs/heads/main/QuestionAnswer.tsv'\n",
        "\n",
        "df = pd.read_csv(url, sep=\"\\t\")\n",
        "\n",
        "\n",
        "# base_url = \"https://api.telegram.org/bot1822361510:AAE2y6B5vQy35bFu66QNk28_jWoRoGlMc5g\"     FOR PUSH TO GITHUB\n",
        "\n",
        "\n",
        "\n",
        "def read_msg(offset):\n",
        "\n",
        "  parameters = {\n",
        "      \"offset\" : offset\n",
        "  }\n",
        "\n",
        "  resp = requests.get(base_url + \"/getUpdates\", data = parameters)\n",
        "  data = resp.json()\n",
        "\n",
        "  print(data)\n",
        "\n",
        "  for result in data[\"result\"]:\n",
        "    send_msg(result)\n",
        "\n",
        "  if data[\"result\"]:\n",
        "    return data[\"result\"][-1][\"update_id\"] + 1\n",
        "\n",
        "\n",
        "\n",
        "def auto_answer(message):\n",
        "  answer = df.loc[df['Question'].str.lower() == message.lower()]\n",
        "\n",
        "  if not answer.empty:\n",
        "      answer = answer.iloc[0]['Answer']\n",
        "      return answer\n",
        "  else:\n",
        "      return \"Sorry, I could not understand you !!! I am still learning and try to get better in answering.\"\n",
        "\n",
        "\n",
        "\n",
        "def send_msg(message):\n",
        "  text = message[\"message\"][\"text\"]\n",
        "  message_id = message[\"message\"][\"message_id\"]\n",
        "  answer = auto_answer(text)\n",
        "\n",
        "  parameters = {\n",
        "      \"chat_id\" : \"-402253018\",\n",
        "      \"text\" : answer,\n",
        "      \"reply_to_message_id\" : message_id\n",
        "  }\n",
        "\n",
        "  resp = requests.get(base_url + \"/sendMessage\", data = parameters)\n",
        "  print(resp.text)\n",
        "\n",
        "offset = 0\n",
        "\n",
        "while True:\n",
        "  offset = read_msg(offset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-0RF3tMQpHJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJcOsWB2XsQJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PNwYOQ2XsMo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FaR2_CVXsKN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU7-mraIXsH6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEdEw9GJXsDq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUpauk2aXsAK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omuJKg_0Xr9w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGQa7ef2Xr7X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMH1lPNzXr41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw2oy1wDXrwa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo84BFyaXri4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqoQaNnKg-Gh"
      },
      "outputs": [],
      "source": [
        "# Create a project folder and virtual environment\n",
        "mkdir telegram-bot && cd telegram-bot\n",
        "python -m venv venv\n",
        "# source venv/bin/activate  # Linux/macOS\n",
        "venv\\Scripts\\activate     # Windows\n",
        "\n",
        "# Install dependencies\n",
        "pip install python-telegram-bot requests flask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMtXPn4WhGIH"
      },
      "outputs": [],
      "source": [
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"Hello! I'm your bot.\")\n",
        "\n",
        "app = ApplicationBuilder().token(\"YOUR_API_TOKEN\").build()\n",
        "app.add_handler(CommandHandler(\"start\", start))\n",
        "app.run_polling()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NN7O7P4hMAu"
      },
      "outputs": [],
      "source": [
        "!pip install python-telegram-bot --quiet\n",
        "\n",
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "nest_asyncio.apply()  # Allows nested event loops in Jupyter/Colab\n",
        "\n",
        "# Define the command handler\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"Hello! \")\n",
        "\n",
        "# Replace this with your actual bot token\n",
        "BOT_TOKEN = \"7856234649:AAHBv9W4q_NEkRtZ0que606X6eti_TbQPkE\"\n",
        "\n",
        "# Build the app\n",
        "app = ApplicationBuilder().token(BOT_TOKEN).build()\n",
        "app.add_handler(CommandHandler(\"start\", start))\n",
        "\n",
        "# Define async run function\n",
        "async def run_bot():\n",
        "    print(\"Bot is starting...\")\n",
        "    await app.initialize()\n",
        "    await app.start()\n",
        "    await app.updater.start_polling()\n",
        "    print(\"Bot is running. Send /start in Telegram.\")\n",
        "\n",
        "# Run the bot safely in notebook\n",
        "await run_bot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWajYGUhijDB"
      },
      "outputs": [],
      "source": [
        "async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"Available commands:\\n/start - Start the bot\\n/help - Show help\")\n",
        "\n",
        "app.add_handler(CommandHandler(\"help\", help_command))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEt2OyGFkBop"
      },
      "outputs": [],
      "source": [
        "from telegram.ext import MessageHandler, filters\n",
        "\n",
        "async def echo(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_message = update.message.text\n",
        "    await update.message.reply_text(f\"You said: {user_message}\")\n",
        "\n",
        "app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlTpdUAIkFNc"
      },
      "outputs": [],
      "source": [
        "!pip install openai python-dotenv --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#ADD API KEY OF OPEN AI BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IjtHpSIlpU-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2KMctlIkJ8C"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Load OpenAI API key from environment variables\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "async def ai_response(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_question = update.message.text\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_question}]\n",
        "    )\n",
        "    await update.message.reply_text(response.choices[0].message.content)\n",
        "\n",
        "app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, ai_response))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeS0MjAYl9q6"
      },
      "outputs": [],
      "source": [
        "# Wrap in try/except to handle KeyboardInterrupt\n",
        "try:\n",
        "    await run_bot()\n",
        "except asyncio.CancelledError:\n",
        "    await app.stop()\n",
        "    print(\"Bot stopped\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDwaC8x5mQXs"
      },
      "outputs": [],
      "source": [
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops in Jupyter/Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the command handlers (assuming these were defined in previous cells)\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"Hello! \")\n",
        "\n",
        "async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\"Available commands:\\n/start - Start the bot\\n/help - Show help\")\n",
        "\n",
        "async def echo(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_message = update.message.text\n",
        "    await update.message.reply_text(f\"You said: {user_message}\")\n",
        "\n",
        "async def ai_response(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    user_question = update.message.text\n",
        "    # Ensure client is initialized - assuming OPENAI_API_KEY is set via %env\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_question}]\n",
        "    )\n",
        "    await update.message.reply_text(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "# Replace this with your actual bot token (assuming this was defined in a previous cell)\n",
        "BOT_TOKEN = \"7856234649:AAHBv9W4r_NEkRt0que606X6eti_TbQPkE\"\n",
        "\n",
        "# Build the app if it hasn't been built already (this should ideally be done once)\n",
        "# Check if 'app' is in global variables to avoid rebuilding\n",
        "if 'app' not in globals() or app is None:\n",
        "    print(\"Building Application...\")\n",
        "    app = ApplicationBuilder().token(BOT_TOKEN).build()\n",
        "    # Add handlers (assuming these were added in previous cells)\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(CommandHandler(\"help\", help_command))\n",
        "    # Using the echo and ai_response handlers for text messages that are not commands\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo))\n",
        "    # The ai_response handler was added after the echo handler in the original notebook,\n",
        "    # which means echo will be called first for text messages.\n",
        "    # If you want AI response to be the primary handler for text messages,\n",
        "    # you might want to rethink the handler order or logic.\n",
        "    # For now, keeping the original order implied by the notebook cells:\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, ai_response))\n",
        "\n",
        "\n",
        "# Define async run function\n",
        "async def run_bot():\n",
        "    print(\"Attempting to run bot...\")\n",
        "    # Check if the application is already running\n",
        "    if app.running:\n",
        "        print(\"Bot is already running. Stopping first...\")\n",
        "        await app.stop()\n",
        "        await app.shutdown() # Use shutdown for graceful exit\n",
        "\n",
        "    # Initialize if not already initialized\n",
        "    if not app.post_init: # Check if initialization has happened\n",
        "         await app.initialize()\n",
        "         print(\"Application initialized.\")\n",
        "\n",
        "    # Start the application and polling\n",
        "    if not app.running:\n",
        "        print(\"Starting application...\")\n",
        "        await app.start()\n",
        "        print(\"Application started.\")\n",
        "\n",
        "    if app.updater and not app.updater.running:\n",
        "        print(\"Starting polling...\")\n",
        "        await app.updater.start_polling()\n",
        "        print(\"Bot is running. Send /start in Telegram.\")\n",
        "    else:\n",
        "        print(\"Updater is already running or not available.\")\n",
        "\n",
        "\n",
        "# Wrap in try/except to handle KeyboardInterrupt\n",
        "try:\n",
        "    # Attempt to run the bot\n",
        "    await run_bot()\n",
        "except asyncio.CancelledError:\n",
        "    # This exception is raised when the cell execution is interrupted (e.g., by stopping the kernel)\n",
        "    print(\"Detected asyncio.CancelledError. Stopping bot...\")\n",
        "    if 'app' in globals() and app is not None and (app.running or (app.updater and app.updater.running)):\n",
        "        await app.stop()\n",
        "        await app.shutdown()\n",
        "        print(\"Bot stopped gracefully.\")\n",
        "    else:\n",
        "        print(\"Bot was not running or already stopped.\")\n",
        "except Exception as e:\n",
        "    # Catch any other potential exceptions during bot execution\n",
        "    print(f\"An error occurred during bot execution: {e}\")\n",
        "    # Optionally, try to stop the bot in case of other errors as well\n",
        "    if 'app' in globals() and app is not None and (app.running or (app.updater and app.updater.running)):\n",
        "        try:\n",
        "            await app.stop()\n",
        "            await app.shutdown()\n",
        "            print(\"Attempted to stop bot after error.\")\n",
        "        except Exception as stop_e:\n",
        "            print(f\"Error during bot stop after failure: {stop_e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
